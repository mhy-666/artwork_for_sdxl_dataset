{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "      <th>image_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>images/image_1608_19351942.jpg</td>\n",
       "      <td>1942</td>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4623</th>\n",
       "      <td>images/image_5211_1581.jpg</td>\n",
       "      <td>1581</td>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3315</th>\n",
       "      <td>images/image_3350_c 1940.jpg</td>\n",
       "      <td>1940</td>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4431</th>\n",
       "      <td>images/image_4845_1849.jpg</td>\n",
       "      <td>1849</td>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>images/image_260_c 1505.jpg</td>\n",
       "      <td>1505</td>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3414</th>\n",
       "      <td>images/image_3449_19351942.jpg</td>\n",
       "      <td>1942</td>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4551</th>\n",
       "      <td>images/image_5032_probably c 16451656.jpg</td>\n",
       "      <td>1656</td>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5883</th>\n",
       "      <td>images/image_6998_possibly c 1530.jpg</td>\n",
       "      <td>1530</td>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5670</th>\n",
       "      <td>images/image_6681_c 1400.jpg</td>\n",
       "      <td>1400</td>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>images/image_477_19351942.jpg</td>\n",
       "      <td>1942</td>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      file_name  label  \\\n",
       "1573             images/image_1608_19351942.jpg   1942   \n",
       "4623                 images/image_5211_1581.jpg   1581   \n",
       "3315               images/image_3350_c 1940.jpg   1940   \n",
       "4431                 images/image_4845_1849.jpg   1849   \n",
       "247                 images/image_260_c 1505.jpg   1505   \n",
       "...                                         ...    ...   \n",
       "3414             images/image_3449_19351942.jpg   1942   \n",
       "4551  images/image_5032_probably c 16451656.jpg   1656   \n",
       "5883      images/image_6998_possibly c 1530.jpg   1530   \n",
       "5670               images/image_6681_c 1400.jpg   1400   \n",
       "443               images/image_477_19351942.jpg   1942   \n",
       "\n",
       "                                             image_data  \n",
       "1573  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...  \n",
       "4623  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...  \n",
       "3315  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...  \n",
       "4431  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...  \n",
       "247   b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...  \n",
       "...                                                 ...  \n",
       "3414  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...  \n",
       "4551  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...  \n",
       "5883  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...  \n",
       "5670  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...  \n",
       "443   b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...  \n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(data_files, engine='pyarrow')\n",
    "df = df.sample(n=200, random_state=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# load pipelines\n",
    "blip_processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
    "blip_model = Blip2ForConditionalGeneration.from_pretrained(\n",
    "    \"Salesforce/blip2-opt-2.7b\",\n",
    "    torch_dtype=torch.float16,\n",
    "    cache_dir='cache',\n",
    ").to(device)\n",
    "\n",
    "## IMAGE CPATIONING ##\n",
    "def caption_images(input_image):\n",
    "    inputs = blip_processor(images=input_image, return_tensors=\"pt\").to(device, torch.float16)\n",
    "    pixel_values = inputs.pixel_values\n",
    "\n",
    "    generated_ids = blip_model.generate(pixel_values=pixel_values, max_length=50)\n",
    "    generated_caption = blip_processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return generated_caption\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Configs and Mount drive\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "%cd /content\n",
    "\n",
    "if not os.path.exists('/content/drive'):\n",
    "  drive.mount('/content/drive/MyDrive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from PIL import Image\n",
    "import os\n",
    "import io\n",
    "# saves each caption and corresponding image to a metadata.jsonl file\n",
    "local_dir='/content/drive/MyDrive/artwork_dataset/'\n",
    "if not os.path.exists(local_dir):\n",
    "    os.makedirs(local_dir)\n",
    "from tqdm import tqdm\n",
    "paths_and_images = list(df[[\"file_name\", \"image_data\"]].itertuples(index=False, name=None))\n",
    "with open(f'{local_dir}metadata.jsonl', 'w') as outfile:\n",
    "  for path, img in tqdm(paths_and_images):\n",
    "      file_name = os.path.basename(path)\n",
    "      img = Image.open(io.BytesIO(img))\n",
    "      img.save(f\"{local_dir}{file_name}\")\n",
    "      blip_caption=caption_images(img).strip()\n",
    "      entry = {\"file_name\":file_name, \"prompt\": blip_caption}\n",
    "      json.dump(entry, outfile)\n",
    "      outfile.write('\\n')\n",
    "\n",
    "print(f\"\\nYour image captions are ready here: ./metadata.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Specify the path to the metadata.jsonl file\n",
    "metadata_file = '../metadata.jsonl'\n",
    "\n",
    "# Specify the path to the images directory\n",
    "images_directory = './images/'\n",
    "\n",
    "# Read the metadata.jsonl file\n",
    "with open(metadata_file, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Modify the file_name column and save the changes\n",
    "with open(metadata_file, 'w') as f:\n",
    "    for line in lines:\n",
    "        data = json.loads(line)\n",
    "        data['file_name'] = f\"{images_directory}{data['file_name']}\"\n",
    "        f.write(json.dumps(data) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Git hooks.\n",
      "Git LFS initialized.\n"
     ]
    }
   ],
   "source": [
    "!git lfs install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'artwork_for_sdxl'...\n",
      "remote: Enumerating objects: 396, done.\u001b[K\n",
      "remote: Counting objects: 100% (392/392), done.\u001b[K\n",
      "remote: Compressing objects: 100% (391/391), done.\u001b[K\n",
      "remote: Total 396 (delta 87), reused 0 (delta 0), pack-reused 4\u001b[K\n",
      "Receiving objects: 100% (396/396), 91.76 KiB | 11.47 MiB/s, done.\n",
      "Resolving deltas: 100% (87/87), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://huggingface.co/datasets/wintercoming6/artwork_for_sdxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.10/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/codespace/.local/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from datasets) (15.0.0)\n",
      "Collecting pyarrow-hotfix (from datasets)\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.10/site-packages (from datasets) (2.2.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/codespace/.local/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from datasets) (4.66.2)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from datasets) (0.20.3)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.10/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->datasets)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/codespace/.local/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xxhash, pyarrow-hotfix, multidict, frozenlist, dill, async-timeout, yarl, multiprocess, aiosignal, aiohttp, datasets\n",
      "Successfully installed aiohttp-3.9.3 aiosignal-1.3.1 async-timeout-4.0.3 datasets-2.18.0 dill-0.3.8 frozenlist-1.4.1 multidict-6.0.5 multiprocess-0.70.16 pyarrow-hotfix-0.6 xxhash-3.4.1 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.10.13/lib/python3.10/site-packages/datasets/load.py:926: FutureWarning: The repository for artwork_for_sdxl contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at ./artwork_for_sdxl/artwork_for_sdxl.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Loading Dataset Infos from /home/codespace/.cache/huggingface/modules/datasets_modules/datasets/artwork_for_sdxl/a572732b58430944a8a7c583ce5987f7eb9e7cd5986709f8ec1d881cbfadadbd\n",
      "Testing builder 'default' (1/1)\n",
      "Generating dataset artwork_for_sdxl (/home/codespace/.cache/huggingface/datasets/artwork_for_sdxl/default/0.0.0)\n",
      "Downloading and preparing dataset artwork_for_sdxl/default to /home/codespace/.cache/huggingface/datasets/artwork_for_sdxl/default/0.0.0...\n",
      "https://huggingface.co/datasets/wintercoming6/artwork_for_sdxl/resolve/main/metadata.jsonl not found in cache or force_download set to True, downloading to /home/codespace/.cache/huggingface/datasets/downloads/b3375ce42b30043e35728da5fadaecb503503c4705323c7f9b85e012ec7fc267.incomplete\n",
      "Downloading data: 100%|████████████████████| 4.17k/4.17k [00:00<00:00, 11.8MB/s]\n",
      "storing https://huggingface.co/datasets/wintercoming6/artwork_for_sdxl/resolve/main/metadata.jsonl in cache at /home/codespace/.cache/huggingface/datasets/downloads/b3375ce42b30043e35728da5fadaecb503503c4705323c7f9b85e012ec7fc267\n",
      "creating metadata file for /home/codespace/.cache/huggingface/datasets/downloads/b3375ce42b30043e35728da5fadaecb503503c4705323c7f9b85e012ec7fc267\n",
      "Downloading took 0.0 min\n",
      "Checksum Computation took 0.0 min\n",
      "Generating train split\n",
      "Generating train split: 41 examples [00:06,  6.51 examples/s]\n",
      "Dataset artwork_for_sdxl downloaded and prepared to /home/codespace/.cache/huggingface/datasets/artwork_for_sdxl/default/0.0.0. Subsequent calls will reuse this data.\n",
      "Loading Dataset Infos from /home/codespace/.cache/huggingface/modules/datasets_modules/datasets/artwork_for_sdxl/a572732b58430944a8a7c583ce5987f7eb9e7cd5986709f8ec1d881cbfadadbd\n",
      "Dataset card saved at ./artwork_for_sdxl/README.md\n",
      "Test successful.\n"
     ]
    }
   ],
   "source": [
    "!datasets-cli test ./artwork_for_sdxl/artwork_for_sdxl.py --save_info --all_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 41 examples [00:00, 11402.10 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'image_data'],\n",
      "        num_rows: 41\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# 假设 your_arrow_file.arrow 是你的 Arrow 文件路径\n",
    "dataset = load_dataset(\"arrow\", data_files=\"./artwork_for_sdxl/artwork_for_sdxl-train.arrow\")\n",
    "\n",
    "# 现在你可以像使用其他 datasets 数据集一样使用它\n",
    "print(dataset)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
